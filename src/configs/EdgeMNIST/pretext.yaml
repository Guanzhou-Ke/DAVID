# general setting.
views: 2
hidden_dim: 512
seed: 42
verbose: true
wandb: true
experiment_name: "emnist-pretext"
backbone:
  type: 'cnn'
  init_method: 'xavier'
  in_channel: 1
dataset:
  name: 'EdgeMnist'
  class_num: 10
train:
  epochs: 100
  devices: [0, 1, 2, 3]
  batch_size: 512
  optim: "sgd"
  lr: 0.003
  evaluate: 1
  scheduler: 'consine'
  lr_decay_rate: 0.9
  knn_num: 100

consis_enc:
  enable: true
  backbone: 'resnet18'
  in_channel: 1
  max_pooling: false
  activation: 'relu'
  first_norm: false
  output_dim: 512
  project_dim: 128
  temperature: 0.1
  loss_type: 'dclw'
fusion:
  pooling_method: 'mean'
# transformation
training_augmentation:
  hflip: false
  random_resized_crop:
    size: 32
    scale: [0.2, 1.0]
  # for simclr (weak augmentation)
  color_jitter_random_apply:
    p: 0.8
  color_jitter:
    brightness: 0.4
    contrast: 0.4
    saturation: 0.4
    hue: 0.1
  random_grayscale: 
    p: 0.2
  normalize:
    mean: [0.1307]
    std: [0.3081]


valid_augmentation:
  crop_size: 32
  normalize:
    mean: [0.1307]
    std: [0.3081]